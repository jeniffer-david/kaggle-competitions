{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict-Closed-Questions-On-Stack_Overflow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "5VVybeHwrfQn",
        "outputId": "61265a2c-8099-4903-c6e8-0c0edd1ab0d3"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-10f7915e-dac4-4197-9f5b-a0da1ec7fde6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-10f7915e-dac4-4197-9f5b-a0da1ec7fde6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 69 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCkvHSzGq5ht",
        "outputId": "608edd61-9df1-4264-ceb4-af3c6ccae5e9"
      },
      "source": [
        "!kaggle competitions download -c predict-closed-questions-on-stack-overflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading public_leaderboard.7z to /content\n",
            " 24% 5.00M/20.8M [00:00<00:00, 46.8MB/s]\n",
            "100% 20.8M/20.8M [00:00<00:00, 101MB/s] \n",
            "Downloading private%20leaderboard%20raw.7z to /content\n",
            " 38% 9.00M/23.5M [00:00<00:00, 44.0MB/s]\n",
            "100% 23.5M/23.5M [00:00<00:00, 78.1MB/s]\n",
            "Downloading private_leaderboard.7z to /content\n",
            " 60% 14.0M/23.4M [00:00<00:00, 57.6MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 91.7MB/s]\n",
            "Downloading train-sample.csv.zip to /content\n",
            " 85% 41.0M/48.4M [00:00<00:00, 75.2MB/s]\n",
            "100% 48.4M/48.4M [00:00<00:00, 87.4MB/s]\n",
            "Downloading prior_benchmark.csv.zip to /content\n",
            "  0% 0.00/26.2k [00:00<?, ?B/s]\n",
            "100% 26.2k/26.2k [00:00<00:00, 25.2MB/s]\n",
            "Downloading public_leaderboard.csv.zip to /content\n",
            " 95% 29.0M/30.6M [00:00<00:00, 73.9MB/s]\n",
            "100% 30.6M/30.6M [00:00<00:00, 87.8MB/s]\n",
            "Downloading train-sample.gz to /content\n",
            " 93% 43.0M/46.4M [00:00<00:00, 103MB/s] \n",
            "100% 46.4M/46.4M [00:00<00:00, 130MB/s]\n",
            "Downloading train-sample.7z to /content\n",
            " 81% 27.0M/33.3M [00:00<00:00, 107MB/s] \n",
            "100% 33.3M/33.3M [00:00<00:00, 132MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/798k [00:00<?, ?B/s]\n",
            "100% 798k/798k [00:00<00:00, 108MB/s]\n",
            "Downloading private_leaderboard.csv.zip to /content\n",
            " 55% 19.0M/34.3M [00:00<00:00, 57.2MB/s]\n",
            "100% 34.3M/34.3M [00:00<00:00, 98.5MB/s]\n",
            "Downloading private_leaderboard.gz to /content\n",
            " 76% 25.0M/32.9M [00:00<00:00, 37.8MB/s]\n",
            "100% 32.9M/32.9M [00:00<00:00, 74.2MB/s]\n",
            "Downloading train-sample_October_9_2012_v2.gz to /content\n",
            " 90% 54.0M/59.8M [00:00<00:00, 110MB/s] \n",
            "100% 59.8M/59.8M [00:00<00:00, 135MB/s]\n",
            "Downloading public_leaderboard.gz to /content\n",
            " 95% 28.0M/29.4M [00:00<00:00, 49.4MB/s]\n",
            "100% 29.4M/29.4M [00:00<00:00, 84.1MB/s]\n",
            "Downloading 2012-07%20Stack%20Overflow.7z to /content\n",
            "100% 6.19G/6.20G [02:10<00:00, 51.3MB/s]\n",
            "100% 6.20G/6.20G [02:10<00:00, 50.9MB/s]\n",
            "Downloading train-sample_October_9_2012_v2.7z to /content\n",
            "100% 42.9M/42.9M [00:00<00:00, 36.2MB/s]\n",
            "\n",
            "Downloading train-sample.zip to /content\n",
            " 89% 43.0M/48.5M [00:00<00:00, 58.0MB/s]\n",
            "100% 48.5M/48.5M [00:00<00:00, 62.0MB/s]\n",
            "Downloading basic_benchmark.csv.zip to /content\n",
            "  0% 0.00/3.23M [00:00<?, ?B/s]\n",
            "100% 3.23M/3.23M [00:00<00:00, 106MB/s]\n",
            "Downloading train-sample_October_9_2012_v2.csv.zip to /content\n",
            " 87% 54.0M/62.4M [00:00<00:00, 45.6MB/s]\n",
            "100% 62.4M/62.4M [00:01<00:00, 63.7MB/s]\n",
            "Downloading public_leaderboard.zip to /content\n",
            " 56% 9.00M/16.0M [00:00<00:00, 51.1MB/s]\n",
            "100% 16.0M/16.0M [00:00<00:00, 63.3MB/s]\n",
            "Downloading private_leaderboard.zip to /content\n",
            " 73% 25.0M/34.4M [00:00<00:00, 77.1MB/s]\n",
            "100% 34.4M/34.4M [00:00<00:00, 99.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkWIoBobFTXV",
        "outputId": "b2e3206a-9b45-43ef-f9b3-7a54974c9dc2"
      },
      "source": [
        "!unzip /content/train-sample.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train-sample.zip\n",
            "  inflating: train-sample.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLRYY547ry0E"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/'):\n",
        "    for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))\n",
        "        if filename == 'train-sample.csv':\n",
        "            train_df = pd.read_csv(os.path.join(dirname, filename)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad-RDDqvExjj"
      },
      "source": [
        "train_data = train_df.drop(columns=['OwnerUserId','PostId','PostCreationDate','OwnerCreationDate','ReputationAtPostCreation','OwnerUndeletedAnswerCountAtPostTime','PostClosedDate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nShNwA1HFl5Y",
        "outputId": "2773b273-9400-4e9f-eaa9-f9865ad50d7f"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>BodyMarkdown</th>\n",
              "      <th>Tag1</th>\n",
              "      <th>Tag2</th>\n",
              "      <th>Tag3</th>\n",
              "      <th>Tag4</th>\n",
              "      <th>Tag5</th>\n",
              "      <th>OpenStatus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For Mongodb is it better to reference an objec...</td>\n",
              "      <td>I am building a corpus of indexed sentences in...</td>\n",
              "      <td>mongodb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>open</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to insert schemalocation in a xml document...</td>\n",
              "      <td>i create a xml document with JAXP and search a...</td>\n",
              "      <td>dom</td>\n",
              "      <td>xsd</td>\n",
              "      <td>jaxp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>open</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Too many lookup tables</td>\n",
              "      <td>What are the adverse effects of having too man...</td>\n",
              "      <td>sql-server</td>\n",
              "      <td>database-design</td>\n",
              "      <td>enums</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>open</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is this PHP code in VB.net</td>\n",
              "      <td>I am looking for the vb.net equivalent of this...</td>\n",
              "      <td>php</td>\n",
              "      <td>vb.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>too localized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
              "      <td>With Spring-Data, you can use the @Document an...</td>\n",
              "      <td>mongodb</td>\n",
              "      <td>spring-data</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>open</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...     OpenStatus\n",
              "0  For Mongodb is it better to reference an objec...  ...           open\n",
              "1  How to insert schemalocation in a xml document...  ...           open\n",
              "2                            Too many lookup tables   ...           open\n",
              "3                    What is this PHP code in VB.net  ...  too localized\n",
              "4  Spring-Data mongodb querying multiple classes ...  ...           open\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7d7TDJFuSO"
      },
      "source": [
        "train_data.replace(np.NaN, ' ', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcwdIxszFw_j"
      },
      "source": [
        "train_data['Text'] = train_data['Title'] + ' ' + \\\n",
        "                        train_data['BodyMarkdown'] + ' ' + \\\n",
        "                        train_data['Tag1'] + ' ' + \\\n",
        "                        train_data['Tag2'] + ' ' + \\\n",
        "                        train_data['Tag3'] + ' ' + \\\n",
        "                        train_data['Tag4'] + ' ' + \\\n",
        "                        train_data['Tag5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bFJ20l31FxJJ",
        "outputId": "bfb1a03c-24f5-4374-e5be-f731fdb4d88b"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>BodyMarkdown</th>\n",
              "      <th>Tag1</th>\n",
              "      <th>Tag2</th>\n",
              "      <th>Tag3</th>\n",
              "      <th>Tag4</th>\n",
              "      <th>Tag5</th>\n",
              "      <th>OpenStatus</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For Mongodb is it better to reference an objec...</td>\n",
              "      <td>I am building a corpus of indexed sentences in...</td>\n",
              "      <td>mongodb</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>open</td>\n",
              "      <td>For Mongodb is it better to reference an objec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to insert schemalocation in a xml document...</td>\n",
              "      <td>i create a xml document with JAXP and search a...</td>\n",
              "      <td>dom</td>\n",
              "      <td>xsd</td>\n",
              "      <td>jaxp</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>open</td>\n",
              "      <td>How to insert schemalocation in a xml document...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Too many lookup tables</td>\n",
              "      <td>What are the adverse effects of having too man...</td>\n",
              "      <td>sql-server</td>\n",
              "      <td>database-design</td>\n",
              "      <td>enums</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>open</td>\n",
              "      <td>Too many lookup tables  What are the adverse e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is this PHP code in VB.net</td>\n",
              "      <td>I am looking for the vb.net equivalent of this...</td>\n",
              "      <td>php</td>\n",
              "      <td>vb.net</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>too localized</td>\n",
              "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
              "      <td>With Spring-Data, you can use the @Document an...</td>\n",
              "      <td>mongodb</td>\n",
              "      <td>spring-data</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>open</td>\n",
              "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                               Text\n",
              "0  For Mongodb is it better to reference an objec...  ...  For Mongodb is it better to reference an objec...\n",
              "1  How to insert schemalocation in a xml document...  ...  How to insert schemalocation in a xml document...\n",
              "2                            Too many lookup tables   ...  Too many lookup tables  What are the adverse e...\n",
              "3                    What is this PHP code in VB.net  ...  What is this PHP code in VB.net I am looking f...\n",
              "4  Spring-Data mongodb querying multiple classes ...  ...  Spring-Data mongodb querying multiple classes ...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb2qn8x-jRsE"
      },
      "source": [
        "train_data['Text'] = train_data['Text'].str.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as4P_LZVkHT7"
      },
      "source": [
        "train_data['Output'] = train_data['OpenStatus'].astype('category').cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPlGnKvalQu2"
      },
      "source": [
        "train_data.drop(columns=['Title','BodyMarkdown','Tag1','Tag2','Tag3','Tag4','Tag5','OpenStatus'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RLrG5apVluSm",
        "outputId": "e8ecdb95-28cc-46e1-922d-482903bb2d28"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For Mongodb is it better to reference an objec...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to insert schemalocation in a xml document...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Too many lookup tables  What are the adverse e...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is this PHP code in VB.net I am looking f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spring-Data mongodb querying multiple classes ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Output\n",
              "0  For Mongodb is it better to reference an objec...       3\n",
              "1  How to insert schemalocation in a xml document...       3\n",
              "2  Too many lookup tables  What are the adverse e...       3\n",
              "3  What is this PHP code in VB.net I am looking f...       4\n",
              "4  Spring-Data mongodb querying multiple classes ...       3"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XstMp1YUlnWs"
      },
      "source": [
        "# Multi-class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXO5IsmbmCv1"
      },
      "source": [
        "1. Preprocessing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IOzAbHXmeeb"
      },
      "source": [
        "import torch\n",
        "\n",
        "inps = train_data['Text'].values\n",
        "tgts = train_data['Output'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeg74ZVjnuoe"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')  # can we try other tokenizers?\n",
        "train_iter = iter(zip(tgts, inps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQECC8Z6sBZ-",
        "outputId": "46ac8cda-65a8-48f6-d5bf-1c3608afbd8e"
      },
      "source": [
        "next(train_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " 'For Mongodb is it better to reference an object or use a natural String key? I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it\\'s a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of? mongodb')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLlgn0yNsPy9"
      },
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "train_iter = iter(zip(tgts, inps))\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD2bYXHrqpcI",
        "outputId": "a645382b-bae1-4855-d1ac-2d9a2c56a37b"
      },
      "source": [
        "vocab(['here', 'is', 'an', 'example'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[109, 12, 36, 155]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fF6Qu8iqsSs"
      },
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmGgGoeqq3Rv",
        "outputId": "a1b9990c-6e1b-40f8-cafd-a2a0cb459177"
      },
      "source": [
        "text_pipeline('here is the an example')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[109, 12, 5, 36, 155]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU70Xnovq8tE",
        "outputId": "48834c67-37a2-4e68-94ef-0ca4baa43d5e"
      },
      "source": [
        "label_pipeline('0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws1zB-p-uEUN",
        "outputId": "4dfc3925-2b8b-49fe-95de-1f3d0977a887"
      },
      "source": [
        "torch.tensor(text_pipeline('here is the an example'), dtype=torch.int64).size(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l10rVY3ytGh8"
      },
      "source": [
        "**Collate_fn** âœˆ\n",
        "With this collate_fn function, you always gonna have a tensor where all your examples have the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCpNfHbdrE5P"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))  # returns the number of tokens in an example.\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)  # returns the cumulative sum of elements of input in the dimension dim.\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "train_iter = iter(zip(tgts, inps))\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch) # what happens if we increase batch size?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt0T__ZY_UIt"
      },
      "source": [
        "## 1. Bag of Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03sdgFlD_XU-"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZabEvB8AatO"
      },
      "source": [
        "train_iter = iter(zip(tgts, inps))\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMpM6fmAmN9"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXU-LxWEA_JO",
        "outputId": "fbab7480-31c9-421e-bb1c-9f29ca1c7f9b"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter = iter(zip(tgts, inps))\n",
        "#train_iter, test_iter = iter(zip(tgts, inps)), iter(zip(tgts_test, inps_test))\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "#test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "#                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 2083 batches | accuracy    0.541\n",
            "| epoch   1 |  1000/ 2083 batches | accuracy    0.598\n",
            "| epoch   1 |  1500/ 2083 batches | accuracy    0.608\n",
            "| epoch   1 |  2000/ 2083 batches | accuracy    0.624\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 43.65s | valid accuracy    0.629 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 2083 batches | accuracy    0.634\n",
            "| epoch   2 |  1000/ 2083 batches | accuracy    0.635\n",
            "| epoch   2 |  1500/ 2083 batches | accuracy    0.633\n",
            "| epoch   2 |  2000/ 2083 batches | accuracy    0.638\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 43.60s | valid accuracy    0.633 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 2083 batches | accuracy    0.643\n",
            "| epoch   3 |  1000/ 2083 batches | accuracy    0.644\n",
            "| epoch   3 |  1500/ 2083 batches | accuracy    0.648\n",
            "| epoch   3 |  2000/ 2083 batches | accuracy    0.646\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 43.96s | valid accuracy    0.638 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 2083 batches | accuracy    0.650\n",
            "| epoch   4 |  1000/ 2083 batches | accuracy    0.653\n",
            "| epoch   4 |  1500/ 2083 batches | accuracy    0.655\n",
            "| epoch   4 |  2000/ 2083 batches | accuracy    0.656\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 44.00s | valid accuracy    0.637 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 2083 batches | accuracy    0.664\n",
            "| epoch   5 |  1000/ 2083 batches | accuracy    0.669\n",
            "| epoch   5 |  1500/ 2083 batches | accuracy    0.668\n",
            "| epoch   5 |  2000/ 2083 batches | accuracy    0.668\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 43.12s | valid accuracy    0.655 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 2083 batches | accuracy    0.671\n",
            "| epoch   6 |  1000/ 2083 batches | accuracy    0.667\n",
            "| epoch   6 |  1500/ 2083 batches | accuracy    0.672\n",
            "| epoch   6 |  2000/ 2083 batches | accuracy    0.665\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 43.84s | valid accuracy    0.647 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 2083 batches | accuracy    0.669\n",
            "| epoch   7 |  1000/ 2083 batches | accuracy    0.671\n",
            "| epoch   7 |  1500/ 2083 batches | accuracy    0.670\n",
            "| epoch   7 |  2000/ 2083 batches | accuracy    0.673\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 44.52s | valid accuracy    0.654 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 2083 batches | accuracy    0.673\n",
            "| epoch   8 |  1000/ 2083 batches | accuracy    0.674\n",
            "| epoch   8 |  1500/ 2083 batches | accuracy    0.671\n",
            "| epoch   8 |  2000/ 2083 batches | accuracy    0.669\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 44.68s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 2083 batches | accuracy    0.672\n",
            "| epoch   9 |  1000/ 2083 batches | accuracy    0.673\n",
            "| epoch   9 |  1500/ 2083 batches | accuracy    0.667\n",
            "| epoch   9 |  2000/ 2083 batches | accuracy    0.672\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 44.63s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 2083 batches | accuracy    0.670\n",
            "| epoch  10 |  1000/ 2083 batches | accuracy    0.676\n",
            "| epoch  10 |  1500/ 2083 batches | accuracy    0.671\n",
            "| epoch  10 |  2000/ 2083 batches | accuracy    0.667\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 44.38s | valid accuracy    0.653 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHt6dvlkLMsM"
      },
      "source": [
        "# print('Checking the results of test dataset.')\n",
        "# accu_test = evaluate(test_dataloader)\n",
        "# print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIhU3H6uKkvu"
      },
      "source": [
        "## 2. CNN Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJvb-PZPBLZj"
      },
      "source": [
        "class CNNClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(CNNClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}